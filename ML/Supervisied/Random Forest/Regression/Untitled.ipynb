{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cfa3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9290a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('petrol_consumption.csv')\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74860ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c70efd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac7f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fa35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rr = RandomForestRegressor(n_estimators=5,random_state=0)\n",
    "#rr = GradientBoostingRegressor(max_depth=2,n_estimators =8,learning_rate=1.0)\n",
    "#rr= AdaBoostRegressor(n_estimators = 32,learning_rate=1)\n",
    "#rr = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcce07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rr.fit(X_train, y_train)\\ny_pred = rr.predict(X_test)\\nfrom sklearn import metrics\\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rr.fit(X_train, y_train)\n",
    "y_pred = rr.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed49f6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for 1 estimators :78.05765401146284\n",
      "RMSE for 2 estimators :104.48093925049996\n",
      "RMSE for 3 estimators :58.11611972508855\n",
      "RMSE for 4 estimators :138.75339598564068\n",
      "RMSE for 5 estimators :67.78738925774954\n",
      "RMSE for 6 estimators :66.83012919492133\n",
      "RMSE for 7 estimators :61.306204795145305\n",
      "RMSE for 8 estimators :64.92673956680001\n",
      "RMSE for 9 estimators :70.48547232606006\n"
     ]
    }
   ],
   "source": [
    "#Finding the number of n_estimators\n",
    "\n",
    "for n in range(1,10):\n",
    "      rr =AdaBoostRegressor(n_estimators=n,learning_rate=1)\n",
    "      rr.fit(X_train, y_train)\n",
    "      y_pred = rr.predict(X_test)\n",
    "      print(\"RMSE for %s estimators :%s\" %(n,np.sqrt(metrics.mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f249e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor n in range(1,25):\\n      rr =GradientBoostingRegressor(max_depth=1,n_estimators =n,learning_rate=1)\\n      rr.fit(X_train, y_train)\\n      y_pred = rr.predict(X_test)\\n      print(\"RMSE for %s estimators :%s\" %(n,np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for n in range(1,25):\n",
    "      rr =GradientBoostingRegressor(max_depth=1,n_estimators =n,learning_rate=1)\n",
    "      rr.fit(X_train, y_train)\n",
    "      y_pred = rr.predict(X_test)\n",
    "      print(\"RMSE for %s estimators :%s\" %(n,np.sqrt(metrics.mean_squared_error(y_test, y_pred))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de0dc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(n_estimators=5, random_state=0)  :  73.54579525710496\n",
      "GradientBoostingRegressor(learning_rate=1.0, max_depth=1, n_estimators=8)  :  55.55616963571921\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...)  :  64.79119593270755\n",
      "AdaBoostRegressor(learning_rate=1, n_estimators=3, random_state=0)  :  89.11615207094313\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=5,random_state=0)\n",
    "gbr = GradientBoostingRegressor(max_depth=1,n_estimators =8,learning_rate=1.0)\n",
    "xgb_r = XGBRegressor()\n",
    "abr= AdaBoostRegressor(n_estimators = 3,learning_rate=1,random_state=0)\n",
    "d1={}\n",
    "\n",
    "for rr in rfr,gbr,xgb_r,abr:\n",
    "    rr.fit(X_train, y_train)\n",
    "    y_pred = rr.predict(X_test)\n",
    "    d1[rr]= np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "for k,v in d1.items():\n",
    "    print(k,\" : \",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ad06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
